# -*- coding: utf-8 -*-
"""Churn_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yniRwybhDsbNJTIDqY5b_e6R7H6zSjW9
"""

import pandas as pd
import numpy as np

df = pd.read_csv('churn_data.csv')
df

df1 = df.copy()
df1.columns = df1.columns.str.lower().str.replace(' ','_')

categorical_cols = list(df1.dtypes[df1.dtypes == 'object'].index)

for v in categorical_cols:
  df1[v] = df1[v].str.lower().str.replace(' ','_')

df1

df1.dtypes

df2 = df1.copy()
df2.totalcharges = pd.to_numeric(df2.totalcharges, errors='coerce')

df2.totalcharges = df2.totalcharges.fillna(0)

df2['churn']

df2.churn = (df2.churn != 'no').astype('int')

df2.churn

from sklearn.model_selection import train_test_split

train_set_full, test_set = train_test_split(df2, test_size=0.2, random_state=1, shuffle=True)

train_set, val_set = train_test_split(df2, test_size=0.25, random_state=1, shuffle=True)

train_set = train_set.reset_index(drop=True)
val_set = val_set.reset_index(drop=True)
test_set = test_set.reset_index(drop=True)

y_train = train_set.churn.values
y_val = val_set.churn.values
y_test = test_set.churn.values

del train_set['churn']
del val_set['churn']
del test_set['churn']

train_set_full.isnull().sum()

global_churn_rate = train_set_full.churn.mean()
round(global_churn_rate,2)

train_set_full.dtypes

numeric = ['tenure', 'monthlycharges', 'totalcharges']

train_set_full.columns

categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',
       'phoneservice', 'multiplelines', 'internetservice',
       'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',
       'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',
       'paymentmethod']

train_set_full[categorical].nunique()

churn_male = train_set_full[train_set_full.gender == 'male'].churn.mean()
churn_male

churn_female = train_set_full[train_set_full.gender == 'female'].churn.mean()
churn_female

train_set_full.partner.value_counts()

churn_partner = train_set_full[train_set_full.partner == 'yes'].churn.mean()
churn_partner

churn_no_partner = train_set_full[train_set_full.partner == 'no'].churn.mean()
churn_no_partner

train_set_full.groupby('gender').churn.agg(['mean', 'count'])

for v in categorical:
  df_group = train_set_full.groupby(v).churn.agg(['mean', 'count'])
  df_group['diff'] = df_group['mean'] - global_churn_rate
  df_group['risk_ratio'] = df_group['mean']/global_churn_rate

from sklearn.metrics import mutual_info_score

def mutual_info_churn_score(series):
  mutual_info_score(series, train_set_full.churn)

train_set_full[categorical].apply(mutual_info_churn_score)

mutual_info_score(train_set_full.gender, train_set_full.churn)

mi = train_set_full[categorical].apply(lambda x: mutual_info_score(x, train_set_full.churn))
mi.sort_values(ascending=False)

train_set_full[numeric].corrwith(train_set_full.churn)

from sklearn.feature_extraction import DictVectorizer

dv = DictVectorizer(sparse=False)

train_dicts = train_set[categorical + numeric].to_dict(orient='records')
X_train = dv.fit_transform(train_dicts)

val_dicts = val_set[categorical + numeric].to_dict(orient='records')
X_val = dv.fit_transform(val_dicts)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model.fit(X_train, y_train)

y_pred = model.predict(X_train)

df_result = pd.DataFrame()

df_result['prediction'] = y_pred
df_result['actual'] = y_train
df_result['correct'] = y_pred == y_train

df_result

df_result['correct'].mean()

y_pred = model.predict_proba(X_train)
y_pred

decision = (y_pred[:,1] >= 0.5).astype(int)
decision.shape

df_result2 = pd.DataFrame()
y_pred = model.predict_proba(X_val)
df_result2['probability'] = y_pred[:,1]
decision = (y_pred[:,1] >= 0.5).astype(int)
df_result2['prediction'] = decision
df_result2['actual'] = y_val
df_result2['correct'] = df_result2['prediction'] == y_val

df_result2

df_result2['correct'].mean()

model.coef_

dv.get_feature_names_out()

dict(zip(dv.get_feature_names_out(), model.coef_[0].round(3)))

"""Using the Model"""

dicts_full_train = train_set_full[categorical + numeric].to_dict(orient='records')

dv = DictVectorizer(sparse=False)

X_full_train = dv.fit_transform(dicts_full_train)

y_full_train = train_set_full.churn.values

model = LogisticRegression()
model.fit(X_full_train, y_full_train)

dicts_test = test_set[categorical + numeric].to_dict(orient='records')
X_test = dv.transform(dicts_test)

y_pred = model.predict_proba(X_test)

churn_decision = (y_pred[:,1] >= 0.5).astype(int)

customer = dicts_test[10]
customer

customer_data = dv.transform([customer])

model.predict_proba(customer_data)[:,1]

y_test[10]

from sklearn.metrics import accuracy_score

threshold = np.linspace(0, 1, 31)

scores = []
for t in threshold:
  churn_decision = (y_pred[:,1] >= t).astype(int)
  acc = accuracy_score(y_test, churn_decision)
  scores.append(acc)

import matplotlib.pyplot as plt
plt.plot(threshold, scores)

"""Saving the Model"""

import pickle

output_file = 'churn_model.bin'

with open(output_file, 'wb') as f_out:
  pickle.dump((dv, model), f_out)

print('Model is saved to', output_file)
